{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMCTuning\n",
    "\n",
    "Author: <b>Ignacio Peis</b>\n",
    "\n",
    "*Note*: All the gifs can be obtained using the scripts in '../examples/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes some illustrative examples that will help in understanding why tuning the hyperparameters with HMCTuning is effective. Although some background in Hamiltonian Monte Carlo might be helpful, all you need to know is explained in the Introduction section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "When sampling with HMC, you have to set some hyperparameters:\n",
    "\n",
    "* Step sizes $\\mathbf{\\epsilon}$. Matrix with dims $(T,D)$. Different step sizes can be learned to be applied within each state of the chains.\n",
    "* Momentum variances, $M$. Matrix with dims $(T, D)$.\n",
    "* An inflation/scale parameter $\\mathbf{s}$, that can be a scalar or a vector with dims $D$ so that different inflations can be applied per dimension.\n",
    "\n",
    "\n",
    "You can observe in these gifs how the initial proposal affects the sampling procedure. In the examples, the proposal is cyclically changed to show visually demonstrate that, when the proposal is tight, chains will get stuck in local density regions or modes, and therefore, will not explore the whole density (as desired).\n",
    "<p float=\"center\">\n",
    "    <img src=\"../figs/cycle/gaussian_mixture/samples.gif\" width=\"300\" align=\"center\">     &emsp;\n",
    "    <img src=\"../figs/cycle/wave/samples.gif\" width=\"300\" align=\"center\">\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first distribution (Mixture of Gaussians), a proper initial proposal is a zero-centered Gaussian. The chains reach all the modes. As you might observe, the first state update is a big step, and then smaller steps are applied to refine the final sample $x^{(T)}$ ($T=5$ in this example).\n",
    "<p float=\"center\">\n",
    "    <img src=\"../figs/chains/gaussian_mixture/samples.gif\" width=\"300\" align=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second density (named \"wave\") choosing the same centered, low variance proposal, chains will get stuck in a small region:\n",
    "<p float=\"center\">\n",
    "    <img src=\"../figs/chains/wave/samples_stuck.gif\" width=\"300\" align=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we define a wider horizontal variance (for instance, [0.1, 20.0]), the proposal will cover better the wave density. \n",
    "<p float=\"center\">\n",
    "    <img src=\"../figs/chains/wave/samples_wide.gif\" width=\"300\" align=\"center\">\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several questions come up here: \n",
    "1. Could we automatically tune that initial proposal? \n",
    "2. Rather than considering a scalar step size, could we automatically tune the step sizes applied in each dimension, for each state of the chain? \n",
    "3. Rather than considering a single momentum distribution, could we tune the variances per dimension and state to find a better distribution?\n",
    "\n",
    "The answer is yes. Let's fit the previous HMC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the HMC\n",
    "In the following Figure you can observe the optimization of the hyperparameters for the wave density. As it is clearly appreciated, starting from a tight initial proposal, only the scale factor applied to horizontal dimension automatically increases in order to inflate the proposal.\n",
    "\n",
    "<p float=\"center\">\n",
    "    <img src=\"../figs/training/wave/samples.gif\" width=\"600\" align=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following Figure, you can observe that for the Gaussian Mixture, starting with the zero-centered proposal, the step sizes start shrinking for the latest steps of the chains, while the first step converges to the highest value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does it work?\n",
    "\n",
    "Let's go with the Maths. You can find more details in [our paper](https://arxiv.org/pdf/2202.04599.pdf), but let me recap here. As told above, the HMC objective is in the form:\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{x})\n",
    "$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
